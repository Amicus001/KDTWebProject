{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from konlpy.tag import Mecab, Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.pkl', 'rb') as f:\n",
    "    vocab_emotion = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22560"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = {token: idx for idx, token in enumerate(vocab_emotion)}\n",
    "decode = {idx: token for idx, token in enumerate(vocab_emotion)}\n",
    "\n",
    "UNK = encode.get('<UNK>')\n",
    "PAD = encode.get('<PAD>')\n",
    "UNK, PAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, n_vocab, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding =nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim,hidden_dim, n_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 8) #출력 크기 = 7: 7중 클래스 분류\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        output = self.fc(output[:,-1,:])\n",
    "        output = self.sigmoid(output) #sigmoid\n",
    "        return output\n",
    "    \n",
    "model_emotion = torch.load('model2.pth').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences_emotion(sequences, max_len, pad_token):\n",
    "    padded = []\n",
    "    # for seq in sequences:\n",
    "    #     if seq is None: # 시퀀스가 none이라면 패딩하지 않고 건너뛰기\n",
    "    #         continue\n",
    "    #     if len(seq)<max_len:\n",
    "    #         seq = seq+[pad_token] * (max_len - len(seq))\n",
    "    #     else:\n",
    "    #         seq = seq[:max_len]\n",
    "    #     padded.append(seq)\n",
    "    \n",
    "    seqlen = len(sequences)\n",
    "\n",
    "\n",
    "    for i in range(seqlen):\n",
    "        padded.append(sequences[i]) if i < seqlen else padded.append(pad_token)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(model, sentence, max_len, device, pad_token):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        sentence = [encode[word] if word in encode else encode['<UNK>'] for word in sentence]\n",
    "        padded_sentence = pad_sequences_emotion(sentence, max_len, pad_token)\n",
    "        padded_sentence = torch.tensor(padded_sentence, dtype=torch.long, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "        output = model(padded_sentence)\n",
    "\n",
    "        predicted_class = torch.argmax(output).item()\n",
    "    \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이', '것', '은', '영화', '입니다', '.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.morphs('이것은영화입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '이것은영화입니다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emotion(model_emotion, tokenizer.morphs(sentence), 64, device, PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
