{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faster-whisper\n",
    "import whisperx\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "audio = 'Recording.m4a'\n",
    "batch_size = 16\n",
    "compute_type = 'float16'\n",
    "model_size = \"large-v3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --force-reinstall \"faster-whisper @ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/m-bain/whisperx.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@article{bain2022whisperx,\n",
    "  title={WhisperX: Time-Accurate Speech Transcription of Long-Form Audio},\n",
    "  author={Bain, Max and Huh, Jaesung and Han, Tengda and Zisserman, Andrew},\n",
    "  journal={INTERSPEECH 2023},\n",
    "  year={2023}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.2.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../home/server/.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.2.2. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "model = whisperx.load_model(model_size, device, compute_type=compute_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_nd = whisperx.load_audio(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = model.transcribe(audio, batch_size=batch_size, language='ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segments': [{'text': ' 음성 인식 테스트 해보기 만약 음성이 잘 인식된다면 이 문장이 제대로 나오겠지',\n",
       "   'start': 0.623,\n",
       "   'end': 6.186}],\n",
       " 'language': 'ko'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': ' 음성 인식 테스트 해보기 만약 음성이 잘 인식된다면 이 문장이 제대로 나오겠지', 'start': 0.623, 'end': 6.186}]\n"
     ]
    }
   ],
   "source": [
    "print(result[\"segments\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kresnik/wav2vec2-large-xlsr-korean were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at kresnik/wav2vec2-large-xlsr-korean and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segments': [{'start': 0.623,\n",
       "   'end': 6.005,\n",
       "   'text': ' 음성 인식 테스트 해보기 만약 음성이 잘 인식된다면 이 문장이 제대로 나오겠지',\n",
       "   'words': [{'word': '음성', 'start': 0.623, 'end': 1.145, 'score': 0.0},\n",
       "    {'word': '인식', 'start': 1.266, 'end': 1.346, 'score': 0.0},\n",
       "    {'word': '테스트', 'start': 1.446, 'end': 1.788, 'score': 0.0},\n",
       "    {'word': '해보기', 'start': 1.868, 'end': 2.069, 'score': 0.0},\n",
       "    {'word': '만약', 'start': 2.27, 'end': 2.631, 'score': 0.023},\n",
       "    {'word': '음성이', 'start': 2.671, 'end': 2.973, 'score': 0.001},\n",
       "    {'word': '잘', 'start': 3.073, 'end': 3.294, 'score': 0.0},\n",
       "    {'word': '인식된다면', 'start': 3.354, 'end': 4.278, 'score': 0.0},\n",
       "    {'word': '이', 'start': 4.62, 'end': 4.7, 'score': 0.005},\n",
       "    {'word': '문장이', 'start': 4.76, 'end': 5.202, 'score': 0.028},\n",
       "    {'word': '제대로', 'start': 5.302, 'end': 5.604, 'score': 0.003},\n",
       "    {'word': '나오겠지', 'start': 5.664, 'end': 6.005, 'score': 0.001}]}],\n",
       " 'word_segments': [{'word': '음성', 'start': 0.623, 'end': 1.145, 'score': 0.0},\n",
       "  {'word': '인식', 'start': 1.266, 'end': 1.346, 'score': 0.0},\n",
       "  {'word': '테스트', 'start': 1.446, 'end': 1.788, 'score': 0.0},\n",
       "  {'word': '해보기', 'start': 1.868, 'end': 2.069, 'score': 0.0},\n",
       "  {'word': '만약', 'start': 2.27, 'end': 2.631, 'score': 0.023},\n",
       "  {'word': '음성이', 'start': 2.671, 'end': 2.973, 'score': 0.001},\n",
       "  {'word': '잘', 'start': 3.073, 'end': 3.294, 'score': 0.0},\n",
       "  {'word': '인식된다면', 'start': 3.354, 'end': 4.278, 'score': 0.0},\n",
       "  {'word': '이', 'start': 4.62, 'end': 4.7, 'score': 0.005},\n",
       "  {'word': '문장이', 'start': 4.76, 'end': 5.202, 'score': 0.028},\n",
       "  {'word': '제대로', 'start': 5.302, 'end': 5.604, 'score': 0.003},\n",
       "  {'word': '나오겠지', 'start': 5.664, 'end': 6.005, 'score': 0.001}]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
