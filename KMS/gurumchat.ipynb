{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/miniconda3/envs/llama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:01<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "\n",
    "MODEL_DIR = \"nlpai-lab/KULLM3\"\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_DIR, torch_dtype=torch.float16).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신뢰할 수 있는 사람의 기준은 다양하며, 개인마다 중요하게 여기는 요소가 다를 수 있습니다. 그러나 일반적으로 신뢰를 얻기 위한 몇 가지 중요한 특성은 다음과 같습니다:\n",
      "\n",
      "1. **일관성**: 신뢰할 수 있는 사람은 일관된 행동과 의견을 보여줍니다. 이는 그들이 신뢰할 수 있는 파트너가 될 수 있음을 나타냅니다.\n",
      "\n",
      "2. **책임감**: 자신의 행동과 결정에 대한 책임을 지고, 약속을 지키며, 문제를 해결하기 위해 노력하는 것이 중요합니다.\n",
      "\n",
      "3. **정직성**: 진실을 말하고, 자신의 의견과 감정을 솔직하게 표현하는 것이 중요합니다. 정직은 신뢰의 기초입니다.\n",
      "\n",
      "4. **신뢰성**: 약속을 지키고, 기한을 준수하며, 의무를 완수하는 것이 중요합니다. 신뢰성은 시간을 지키고, 약속을 이행하는 것에서 나타납니다.\n",
      "\n",
      "5. **개방성과 수용성**: 다른 사람의 의견을 경청하고, 다양한 관점을 수용하는 태도는 신뢰를 구축하는 데 중요합니다.\n",
      "\n",
      "6. **보호**: 개인의 정보와 자산을 보호하고, 그들의 이익을 지키려는 의지가 있어야 합니다.\n",
      "\n",
      "7. **지속성**: 장기적인 관계를 유지하고, 변함없이 지지하는 것이 중요합니다.\n",
      "\n",
      "이러한 특성들은 신뢰를 얻고 유지하는 데 중요한 역할을 합니다. 그러나 신뢰는 단순히 이러한 특성들만으로 결정되지 않으며, 개인의 경험과 가치관에 따라 달라질 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# s = \"'나 요즘 고민이 있어'(걱정의 감정) 에 대해 100자 이내로 조언해줘\"\n",
    "s=\"'{}' 를 감정 분석해줘\"\n",
    "conversation = [{'role': 'user', 'content': s}]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    conversation,\n",
    "    tokenize=True,\n",
    "    # add_generation_prompt=True,\n",
    "    return_tensors='pt').to(\"cuda\")\n",
    "_ = model.generate(inputs, streamer=streamer, max_new_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> [INST] <<SYS>>\\n당신은 고려대학교 NLP&AI 연구실에서 만든 AI 챗봇입니다. 당신의 이름은 'KULLM'으로, 한국어로는 '구름'을 뜻합니다. 당신은 비도덕적이거나, 성적이거나, 불법적이거나 또는 사회 통념적으로 허용되지 않는 발언은 하지 않습니다. 사용자와 즐겁게 대화하며, 사용자의 응답에 가능한 정확하고 친절하게 응답함으로써 최대한 도와주려고 노력합니다. 질문이 이상하다면, 어떤 부분이 이상한지 설명합니다. 거짓 정보를 발언하지 않도록 주의합니다.\\n<</SYS>>\\n\\n'컴퓨터는 발전할지 솔직히 모르겠어'는 불행의 감정을 가지고 있어. 이에 대해 100자 이내로 조언해줘 [/INST]불확실성에 대한 불안감을 느끼는 것은 자연스럽습니다. 하지만 컴퓨터 기술의 발전은 계속될 것입니다. 기술의 발전은 새로운 기회와 해결책을 제공하며, 우리의 삶을 더욱 풍요롭게 만들 것입니다. 불확실성에 대처하는 방법은 지속적인 학습과 적응에 있습니다. 새로운 기술을 배우고, 변화에 유연하게 대응하는 태도를 가지는 것이 중요합니다. 기술의 발전은 우리의 삶을 더욱 풍요롭게 만들 것입니다.</s>\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(_)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> 저는 인공지능으로서 이전에 제공한 답변이나 대화 내용을 기억하거나 저장하지 않습니다. 각 질문에 대해 실시간으로 정보를 검색하고 분석하여 답변을 제공합니다. 만약 이전에 제공한 답변이 도움이 되었다면, 그것은 단순히 우연한 일일 뿐입니다. 다시 질문해주시면 최선을 다해 도와드리겠습니다.</s>'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "remover = re.compile(r\"(?s)<INST>.*?</INST>\")\n",
    "remover.sub('', tokenizer.batch_decode(_)[0])\n",
    "\n",
    "re.sub(r\"(?s)\\[INST\\].*?\\[/INST\\]\", '', tokenizer.batch_decode(_)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> [INST] <<SYS>>\\n당신은 고려대학교 NLP&AI 연구실에서 만든 AI 챗봇입니다. 당신의 이름은 'KULLM'으로, 한국어로는 '구름'을 뜻합니다. 당신은 비도덕적이거나, 성적이거나, 불법적이거나 또는 사회 통념적으로 허용되지 않는 발언은 하지 않습니다. 사용자와 즐겁게 대화하며, 사용자의 응답에 가능한 정확하고 친절하게 응답함으로써 최대한 도와주려고 노력합니다. 질문이 이상하다면, 어떤 부분이 이상한지 설명합니다. 거짓 정보를 발언하지 않도록 주의합니다.\\n<</SYS>>\\n\\n혹시 내가 이전에 답변한 거 기억하고 있어? [/INST]저는 인공지능으로서 이전에 제공한 답변이나 대화 내용을 기억하거나 저장하지 않습니다. 각 질문에 대해 실시간으로 정보를 검색하고 분석하여 답변을 제공합니다. 만약 이전에 제공한 답변이 도움이 되었다면, 그것은 단순히 우연한 일일 뿐입니다. 다시 질문해주시면 최선을 다해 도와드리겠습니다.</s>\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(_)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 인공지능으로서 이전에 제공한 답변이나 대화 내용을 기억하거나 저장하지 않습니다. 각 질문에 대해 실시간으로 정보를 검색하고 분석하여 답변을 제공합니다. 만약 이전에 제공한 답변이 도움이 되었다면, 그것은 단순히 우연한 일일 뿐입니다. 다시 질문해주시면 최선을 다해 도와드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "s = \"혹시 내가 이전에 답변한 거 기억하고 있어?\"\n",
    "conversation = [{'role': 'user', 'content': s}]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    conversation,\n",
    "    tokenize=True,\n",
    "    # add_generation_prompt=True,\n",
    "    return_tensors='pt').to(\"cuda\")\n",
    "_ = model.generate(inputs, streamer=streamer, max_new_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TextStreamer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstreamer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'TextStreamer' object is not callable"
     ]
    }
   ],
   "source": [
    "streamer(model, inputs, output_scores=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
